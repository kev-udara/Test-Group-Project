# dashboard.py â€“ Global UFO + Meteor + Air-Traffic explorer
# ============================================================================
# Streamlit 1.32 â€¢ Bokeh 3 â€¢ Folium 0.15 â€¢ Elasticsearch 8
# ============================================================================

import time
import streamlit as st
import pandas as pd
import numpy  as np
from elasticsearch import Elasticsearch, helpers
from bokeh.plotting import figure
from bokeh.palettes import Category10
from bokeh.models   import (
    ColumnDataSource, LinearAxis, Range1d,
    DatetimeTickFormatter, NumeralTickFormatter, HoverTool,
)
import folium
from folium import CircleMarker
from streamlit_folium import st_folium
from branca.colormap import linear
from bokeh.transform import dodge
import pycountry
import matplotlib.pyplot as plt 
import altair as alt
import seaborn as sns


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Elasticsearch
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ES_HOST = "http://elasticsearch:9200"
INDEX   = "ufo_sightings"
ES      = Elasticsearch([ES_HOST], verify_certs=False)

FIELDS = [
    "Occurred_utc", "location", "shape", "City", "State", "Country",
    "meteor_shower_codes", "days_from_shower_peak",
    "air_traffic_monthly", "light_pollution",
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_country_name(code: str) -> str:
    if not code:
        return code
    country = pycountry.countries.get(alpha_2=code.upper())
    return country.name if country else code


def get_subdivision_name(state_code: str, country_code: str) -> str:
    # Silently ignore invalid or missing inputs
    if not state_code or not country_code:
        return None  # or return "" if that's more appropriate in your context

    iso_code = f"{country_code.upper()}-{state_code.upper()}"
    subdivision = pycountry.subdivisions.get(code=iso_code)

    if subdivision:
        return subdivision.name

    return None  # fallback if the code isn't valid
    

@st.cache_data(show_spinner=False)
def read_index(_cache_buster: float) -> pd.DataFrame:
    """
    Pull the index into a DataFrame and normalise nested fields.
    _cache_buster is a dummy parameter â€“ when its value changes
    Streamlit invalidates the cache so we can force a reload.
    """
    hits = helpers.scan(
        ES,
        index=INDEX,
        query={"_source": FIELDS, "sort": ["_doc"]},
        size=1_500,
        scroll="3m",
    )
    df = pd.DataFrame(h["_source"] for h in hits)

    # Apply state name (row-wise, needs both columns)
    df["State"] = df.apply(lambda row: get_subdivision_name(row["State"], row["Country"]), axis=1)

    # Apply country name (column-wise)
    df["Country"] = df["Country"].apply(get_country_name)
    

    # â”€â”€ normalise list / dict columns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    df["meteor_shower_codes"] = df["meteor_shower_codes"].apply(
        lambda x: x if isinstance(x, list) else [])
    df["days_from_shower_peak"] = df["days_from_shower_peak"].apply(
        lambda x: x if isinstance(x, list) else [])

    if "air_traffic_monthly" in df.columns:
        df["air_traffic_monthly"] = df["air_traffic_monthly"].apply(
            lambda x: x if isinstance(x, dict) else {}
        )
    else:
        df["air_traffic_monthly"] = [{} for _ in range(len(df))]

    
    # â”€â”€ flatten light_pollution â†’ brightness â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "light_pollution" in df.columns:
        df["light_pollution"] = df["light_pollution"].apply(
            lambda d: float(d.get("brightness", np.nan)) if isinstance(d, dict) else np.nan
        )
    else:
        df["light_pollution"] = np.nan


    # â”€â”€ timestamps & conveniences â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    df["ts"]        = (pd.to_datetime(df["Occurred_utc"], errors="coerce", utc=True)
                         .dt.tz_convert(None))
    df["month"]     = df["ts"].dt.to_period("M").dt.to_timestamp()
    df["n_showers"] = df["meteor_shower_codes"].str.len()

    df["traffic_total"]  = df["air_traffic_monthly"].apply(
        lambda d: d.get("total",  np.nan))
    df["traffic_region"] = df["air_traffic_monthly"].apply(
        lambda d: d.get("region"))

    return df

def prune_for_bokeh(tdf: pd.DataFrame, numeric_cols: list[str]) -> pd.DataFrame:
    """Remove rows containing NaN/âˆ in numeric cols and cast to plain float."""
    tdf = (tdf.replace([np.inf, -np.inf], np.nan)
              .dropna(subset=numeric_cols)
              .copy())
    for c in numeric_cols:
        tdf[c] = tdf[c].astype(float)
    return tdf

def add_flags(df: pd.DataFrame) -> pd.DataFrame:
    """Add meteor / flight / unknown boolean columns."""
    df = df.copy()

    # meteor-likely: at least one shower code within Â±2 days of peak
    df["meteor_flag"] = (
        (df["n_showers"] > 0) &
        df["days_from_shower_peak"].apply(
            lambda lst: any(abs(d) <= 2 for d in lst or [])
        )
    )

    # flight-likely: traffic â‰¥ *median of its own region* (skip-na)
    reg_p90 = (df.groupby("traffic_region")["traffic_total"]
                 .transform(lambda s: np.nanpercentile(s, 90)))
    df["flight_flag"] = df["traffic_total"] >= 0.5 * reg_p90

    df["unknown_flag"] = ~(df["meteor_flag"] | df["flight_flag"])
    return df

def bokeh_hover():
    return HoverTool(
        tooltips=[
            ("Month",      "@month{%Y-%m}"),
            ("Sightings",  "@sightings{0,0}"),
            ("Avg showers","@avg_showers{0.0}"),
            ("Avg traffic","@avg_traffic{0,0}"),
        ],
        formatters={"@month": "datetime"},
        mode="vline",
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(layout="wide")
st.title("ğŸ›¸ Global UFO Sightings Explorer")

# â†»  Reload-data button (cache buster) ----------------------------------------
if st.sidebar.button("â†» Reload data"):
    st.session_state["_cache_buster"] = time.time()

cache_buster = st.session_state.get("_cache_buster", 0.0)
df_all = read_index(cache_buster)

if df_all.empty:
    st.error("Index is empty â€“ run ingest first."); st.stop()

# â”€â”€ sidebar filters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
min_date = pd.Timestamp("2006-01-01").date()
max_date = df_all["ts"].dt.date.max()

with st.sidebar:
    dr = st.date_input("Date range", (min_date, max_date))

    # â”€â”€ robust dateâ€‘range handling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # If the user supplies an incomplete or outâ€‘ofâ€‘range selection we keep the
    # previous full range (min_dateÂ â†’Â max_date) so the app never errors out.
    try:
        start_date, end_date = dr
    except Exception:
        start_date, end_date = min_date, max_date

    # Clamp to data extent to avoid "out of range" issues
    if start_date is None or start_date < min_date or start_date > max_date:
        start_date = min_date
    if end_date is None or end_date < min_date or end_date > max_date:
        end_date = max_date

    shape = st.selectbox(
    "Shape",
    ["All"] + sorted([s.capitalize() for s in df_all["shape"].dropna().unique()]))

    # Country filter
    all_countries = sorted(df_all["Country"].dropna().unique())
    country = st.selectbox("Country", ["All"] + all_countries)

    # Filtered states based on selected country
    if country != "All":
        filtered_states = sorted(df_all[df_all["Country"] == country]["State"].dropna().unique())
    else:
        filtered_states = sorted(df_all["State"].dropna().unique())

    state = st.selectbox("State/Province", ["All"] + filtered_states)

    if "City" in df_all.columns:
        filtered_cities = sorted(df_all["City"].dropna().unique())
    else:
        st.error("Column 'City' is missing in the data.")
        st.write("Columns available:", df_all.columns.tolist())
        filtered_cities = []

     # Filtered cities based on selected state/country
    if state != "All":
        filtered_cities = sorted(df_all[
            (df_all["Country"] == country) &
            (df_all["State"] == state)
        ]["City"].dropna().unique())
    elif country != "All":
        filtered_cities = sorted(df_all[
            df_all["Country"] == country
        ]["City"].dropna().unique())
    else:
        filtered_cities = sorted(df_all["City"].dropna().unique())

    filtered_cities = [city.title() for city in filtered_cities]

    city = st.selectbox("City", ["All"] + filtered_cities)

    n_map = st.slider("Points on map", 100, 5_000, 500, 100)


    mask = (
        (df_all.ts >= pd.to_datetime(f"{start_date}T00:00:00")) &
        (df_all.ts <= pd.to_datetime(f"{end_date}T23:59:59"))
    )
    if shape != "All":
        mask &= df_all["shape"] == shape.lower()
    if country != "All":
        mask &= df_all["Country"] == country
    if state != "All":
        mask &= df_all["State"] == state
    if city != "All":
        mask &= df_all["City"] == city.lower()



try:
    df = add_flags(df_all[mask]).copy()
except Exception as e:
    print(f"add_flags failed: {e} â€” falling back to unflagged data")
    df = df_all[mask].copy()
    df["flight_flag"] = False
    df["meteor_flag"] = False
    df["unknown_flag"] = True


st.sidebar.markdown(f"**{len(df)} sightings** matched.")

# One common random-sample for both maps (latest first)
df_sample = df.sort_values("ts", ascending=False).head(n_map)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Tabs
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Detect current tab selection
tab_options = [
    "Meteor-Shower Activity",
    "Air-Traffic Correlation",
    "Light-Pollution Analysis",
    "General Statistics",
]

selected_tab = st.selectbox("Tab Selector", tab_options, key="tab_selector", label_visibility="collapsed")

# Helper: assign tab index to highlight which logic to run
tab_index = tab_options.index(selected_tab)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• Tab 1 â€“ Meteor Showers â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if tab_index == 0:
    st.subheader("ğŸ“ˆ Monthly UFO Sightings vs. Average Meteor Showers")
    ts1 = (df.groupby("month")
             .agg(sightings=("ts","count"), avg_showers=("n_showers","mean"))
             .reset_index())
    ts1 = prune_for_bokeh(ts1, ["sightings","avg_showers"])

    if ts1.empty:
        st.info("No data to plot.")
    else:
        src1             = ColumnDataSource(ts1)
        s_min,s_max      = ts1["sightings"].agg(["min","max"])
        sh_min,sh_max    = ts1["avg_showers"].agg(["min","max"])

        p = figure(x_axis_type="datetime", height=300, sizing_mode="stretch_width")
        p.y_range        = Range1d(s_min-1, s_max+1)
        p.extra_y_ranges = {"sh": Range1d(sh_min-0.2, sh_max+0.2)}
        p.add_layout(LinearAxis(y_range_name="sh",
                                axis_label="Avg # Showers"), "right")
        p.line("month","sightings",   source=src1, line_width=2,
               legend_label="Sightings")
        p.line("month","avg_showers", source=src1, line_width=2,
               color="orange", y_range_name="sh",
               legend_label="Avg # Showers")

        p.xaxis.formatter    = DatetimeTickFormatter(years="%Y")
        p.yaxis[0].formatter = NumeralTickFormatter(format="0")
        p.yaxis[1].formatter = NumeralTickFormatter(format="0.0")
        p.yaxis.axis_label   = "Sightings"
        p.legend.location    = "top_left"
        p.add_tools(bokeh_hover())
        st.bokeh_chart(p)

        # ğŸ“„ explanation directly under the chart
        st.markdown(
            "Compares the **number of UFO sightings per month** with the **average number of meteor showers** "
            "during the same period. This dual-axis line chart helps identify whether spikes in sightings "
            "coincide with increased meteor activity."
        )

        # Create lagged versions of meteor shower data
        ts1["avg_showers_lag1"] = ts1["avg_showers"].shift(1)
        ts1["avg_showers_lag2"] = ts1["avg_showers"].shift(2)

        # Drop NaNs from lagged data (first row or two will have NaN)
        ts1_clean = ts1.dropna(subset=["avg_showers_lag1", "avg_showers_lag2"])

        # Bokeh plot
        src = ColumnDataSource(ts1_clean)

        p = figure(x_axis_type="datetime", height=350, sizing_mode="stretch_width")

        # Sightings (primary y-axis)
        p.line("month", "sightings", source=src, line_width=2, color=Category10[3][0], legend_label="Sightings")

        # Add lagged meteor shower lines (right y-axis)
        p.extra_y_ranges = {"sh": Range1d(
            ts1_clean[["avg_showers", "avg_showers_lag1", "avg_showers_lag2"]].min().min() - 0.2,
            ts1_clean[["avg_showers", "avg_showers_lag1", "avg_showers_lag2"]].max().max() + 0.2
        )}
        p.add_layout(LinearAxis(y_range_name="sh", axis_label="Avg # Showers (Lagged)"), 'right')

        p.line("month", "avg_showers", source=src, line_width=2, color=Category10[3][1],
            legend_label="Meteor Showers (no lag)", y_range_name="sh", line_dash="dotted")

        p.line("month", "avg_showers_lag1", source=src, line_width=2, color=Category10[3][2],
            legend_label="Meteor Showers (lag 1)", y_range_name="sh", line_dash="solid")


        p.xaxis.formatter = DatetimeTickFormatter(months="%b %Y")
        p.yaxis[0].axis_label = "Sightings"
        p.yaxis[1].formatter = NumeralTickFormatter(format="0.0")

        p.legend.location = "top_left"
        p.add_tools(bokeh_hover())

        st.subheader("â³ Lagged Meteor Shower Correlation")

        st.bokeh_chart(p)

        st.markdown(
            "Explores if there's a **delayed effect** where UFO sightings increase **1â€“2 months after** periods of high meteor activity. This can suggest residual atmospheric or observational phenomena related to prior showers."
        )

    # â”€â”€ MAP (meteor vs unexplained) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ—ºï¸ Map: **Meteor-likely** <span style='color:orange;'>â—</span> vs **Unexplained** <span style='color:violet;'>â—</span>", unsafe_allow_html=True)


    fmap1 = folium.Map(location=[20,0], zoom_start=2,
                       tiles="CartoDB dark_matter", control_scale=True)

    layer_meteor  = folium.FeatureGroup(name="<span style='color:orange;'><b>Meteor-likely</b></span>", show=True)
    layer_unknown = folium.FeatureGroup(name="<span style='color:violet;'><b>Unexplained</b></span>", show=True)


    for _, r in df_sample.iterrows():
        lat, lon = r["location"]["lat"], r["location"]["lon"]

        if bool(r.get("meteor_flag", False)):
            folium.CircleMarker(
                [lat, lon], radius=5, color="orange",
                fill=True, fill_opacity=.7
            ).add_to(layer_meteor)

        elif bool(r.get("unknown_flag", False)):
            folium.CircleMarker(
                [lat, lon], radius=5, color="violet",
                fill=True, fill_opacity=.7
            ).add_to(layer_unknown)


    layer_meteor.add_to(fmap1)
    layer_unknown.add_to(fmap1)
    folium.LayerControl(collapsed=False).add_to(fmap1)
    st_folium(fmap1, width=900, height=500)

    st.markdown(
        """
    Shows the **geographic distribution** of recent sightings classified as:
    - **Meteor-likely** (orange) â€“ strong correlation with meteor showers
    - **Unexplained** (violet) â€“ not easily attributed to natural phenomena  
    This map helps spot regional patterns and clusters.
    """
    )

    st.subheader("ğŸ“Š Bar Chart: Count of Meteor-Likely vs. Unexplained Sightings")

    # Count occurrences
    counts = {
        "Meteor-likely": df_sample["meteor_flag"].sum(),
        "Unexplained": df_sample["unknown_flag"].sum()
    }

    # Convert to DataFrame
    df_counts = pd.DataFrame(list(counts.items()), columns=["Type", "Count"])

    # Altair bar chart
    bar_chart = alt.Chart(df_counts).mark_bar().encode(
        x=alt.X("Type:N", title=None),
        y=alt.Y("Count:Q"),
        color=alt.Color("Type:N", scale=alt.Scale(domain=["Meteor-likely", "Unexplained"],
                                                range=["orange", "violet"])),
        tooltip=["Type", "Count"]
    ).properties(
        width=400,
        height=300,
    )

    st.altair_chart(bar_chart, use_container_width=True)

    st.markdown(
        "A simple comparison of the total number of **likely meteor-related sightings** vs. **unexplained sightings** in the current dataset."
    )
    
    df["month"] = pd.to_datetime(df["ts"]).dt.to_period("M").dt.to_timestamp()

    grouped = (
        df.groupby("month")
        .agg(
            meteor_likely=("meteor_flag", "sum"),
            unexplained=("unknown_flag", "sum"),
            avg_showers=("n_showers", "mean")
        )
        .reset_index()
    )

    # Clean data (drop NaNs if any)
    grouped = grouped.dropna()

    # Bokeh plot setup
    src = ColumnDataSource(grouped)

    p = figure(x_axis_type="datetime", height=350, sizing_mode="stretch_width")

    # Add sightings lines (left y-axis)
    p.line("month", "meteor_likely", source=src, color=Category10[3][0],
        line_width=2, legend_label="Meteor-Likely Sightings")
    p.line("month", "unexplained", source=src, color=Category10[3][1],
        line_width=2, legend_label="Unexplained Sightings")

    # Add meteor shower line (right y-axis)
    sh_min, sh_max = grouped["avg_showers"].min(), grouped["avg_showers"].max()
    p.extra_y_ranges = {"showers": Range1d(sh_min - 0.2, sh_max + 0.2)}
    p.add_layout(LinearAxis(y_range_name="showers", axis_label="Avg # Meteor Showers"), "right")

    p.line("month", "avg_showers", source=src, color=Category10[3][2],
        line_width=2, line_dash="dashed", y_range_name="showers",
        legend_label="Avg Meteor Showers")

    # Axis formatting
    p.xaxis.formatter = DatetimeTickFormatter(months="%b %Y")
    p.yaxis[0].axis_label = "Sightings Count"
    p.yaxis[1].formatter = NumeralTickFormatter(format="0.0")
    p.legend.location = "top_left"

    st.subheader("ğŸ“‰ Time Series: Correlation of Average Meteor Showers with Meteor-Likely vs Unexplained Sightings")
    # Display in Streamlit
    st.bokeh_chart(p)
    st.markdown(
            "Compares how **Meteor-likely and Unexplained sightings trend over time** alongside average monthly meteor showers. Helps evaluate whether unexplained sightings follow similar seasonal or environmental patterns."
        )

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• Tab 2 â€“ Air Traffic â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if tab_index == 1:
    st.subheader("ğŸ“ˆ Monthly UFO Counts vs. Average Monthly Air Traffic")

    df["month"] = pd.to_datetime(df["ts"]).dt.to_period("M").dt.to_timestamp()

    ts2 = (df.groupby("month")
             .agg(sightings=("ts", "count"),
                  avg_traffic=("traffic_total", "mean"))
             .reset_index())
    ts2 = prune_for_bokeh(ts2, ["sightings", "avg_traffic"])

    if ts2.empty:
        st.info("No air-traffic data for these filters.")
    else:
        src2 = ColumnDataSource(ts2)
        s_min, s_max = ts2["sightings"].agg(["min", "max"])
        tr_min, tr_max = ts2["avg_traffic"].agg(["min", "max"])

        q = figure(x_axis_type="datetime", height=300, sizing_mode="stretch_width")
        q.y_range = Range1d(s_min - 1, s_max + 1)
        q.extra_y_ranges = {"tr": Range1d(tr_min - 1000, tr_max + 1000)}
        q.add_layout(LinearAxis(y_range_name="tr", axis_label="Avg Air Traffic"), "right")

        q.line("month", "sightings", source=src2, line_width=2, legend_label="Sightings")
        q.line("month", "avg_traffic", source=src2, line_width=2,
               color="blue", y_range_name="tr", legend_label="Avg Air Traffic")

        q.xaxis.formatter = DatetimeTickFormatter(years="%Y")
        q.yaxis[0].formatter = NumeralTickFormatter(format="0")
        q.yaxis[1].formatter = NumeralTickFormatter(format="0,0")
        q.yaxis.axis_label = "Sightings"
        q.legend.location = "top_left"
        q.add_tools(bokeh_hover())
        st.bokeh_chart(q)

        # Prepare monthly data
    df["month"] = pd.to_datetime(df["ts"]).dt.to_period("M").dt.to_timestamp()

    ts2 = (
        df.groupby("month")
        .agg(
            sightings=("ts", "count"),
            avg_traffic=("traffic_total", "mean")
        )
        .reset_index()
    )

    # Create lagged air traffic columns
    ts2["avg_traffic_lag1"] = ts2["avg_traffic"].shift(1)
    ts2["avg_traffic_lag2"] = ts2["avg_traffic"].shift(2)

    ts2 = prune_for_bokeh(ts2, ["sightings", "avg_traffic", "avg_traffic_lag1", "avg_traffic_lag2"])

    if ts2.empty:
        st.info("No air-traffic data for these filters.")
    else:
        src2 = ColumnDataSource(ts2)

        s_min, s_max = ts2["sightings"].agg(["min", "max"])
        tr_all = ts2[["avg_traffic", "avg_traffic_lag1", "avg_traffic_lag2"]]
        tr_min, tr_max = tr_all.min().min(), tr_all.max().max()

        q = figure(x_axis_type="datetime", height=300, sizing_mode="stretch_width")
        q.y_range = Range1d(s_min - 1, s_max + 1)

        # Right y-axis for all traffic curves (original + lagged)
        q.extra_y_ranges = {
            "tr": Range1d(tr_min - 1000, tr_max + 1000)
        }
        q.add_layout(LinearAxis(y_range_name="tr", axis_label="Avg Air Traffic (incl. lags)"), "right")

        # Plot sightings (left y-axis)
        q.line("month", "sightings", source=src2, line_width=2,
               legend_label="Sightings", color="orange")

        # Plot original and lagged air traffic (right y-axis)
        q.line("month", "avg_traffic", source=src2, line_width=2,
               color="blue", y_range_name="tr", legend_label="Air Traffic (no lag)", line_dash="dotted")

        q.line("month", "avg_traffic_lag1", source=src2, line_width=2,
               color="green", y_range_name="tr", legend_label="Air Traffic (lag 1)")

        # Formatting
        q.xaxis.formatter = DatetimeTickFormatter(months="%b %Y")
        q.yaxis[0].formatter = NumeralTickFormatter(format="0")
        q.yaxis[1].formatter = NumeralTickFormatter(format="0,0")
        q.yaxis.axis_label = "Sightings"
        q.legend.location = "top_left"
        q.add_tools(bokeh_hover())

        st.markdown(
        "Compares the **number of UFO sightings per month** with the **average monthly air traffic** (total flights). This dual-axis line chart helps identify potential correlation between airspace activity and sighting reports."
    )

        st.subheader("â³ Lagged Air Traffic Correlation")
        st.bokeh_chart(q)

    st.markdown(
        "Introduces a **1â€“2 month lag** on air traffic data to explore if UFO sightings increase **after previous spikes** in flight volume. Useful for detecting delayed effects or reporting latency."
    )

    # â”€â”€ MAP (flight vs unexplained) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ—ºï¸ Map: **Flight-likely** <span style='color:blue;'>â—</span> vs **Unexplained Sightings** <span style='color:violet;'>â—</span>", unsafe_allow_html=True)

    fmap2 = folium.Map(location=[20, 0], zoom_start=2,
                       tiles="CartoDB dark_matter", control_scale=True)

    layer_flight = folium.FeatureGroup(name="<span style='color:blue;'><b>Flight-likely</b></span>", show=True)
    layer_unknown2 = folium.FeatureGroup(name="<span style='color:violet;'><b>Unexplained</b></span>", show=True)

    for _, r in df_sample.iterrows():
        lat, lon = r["location"]["lat"], r["location"]["lon"]

        if bool(r.get("flight_flag", False)):
            folium.CircleMarker(
                [lat, lon], radius=5, color="blue",
                fill=True, fill_opacity=.7
            ).add_to(layer_flight)

        elif bool(r.get("unknown_flag", False)):
            folium.CircleMarker(
                [lat, lon], radius=5, color="violet",
                fill=True, fill_opacity=.6
            ).add_to(layer_unknown2)

    layer_flight.add_to(fmap2)
    layer_unknown2.add_to(fmap2)
    folium.LayerControl(collapsed=False).add_to(fmap2)
    st_folium(fmap2, width=900, height=500)
    st.markdown("""
    Visualizes the **geographic distribution** of sightings categorized as:
    - **Flight-likely** (blue) â€“ plausibly caused by known air traffic
    - **Unexplained** (violet) â€“ with no clear link to flight paths  
    Helps identify hotspots or areas with consistent unexplained activity.
    """
    )

    st.subheader("ğŸ“Š Bar Chart: Count of Flight-Likely vs. Unexplained Sightings")

    # â”€â”€ Count Bar Chart (Flight vs Unexplained) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    counts2 = {
        "Flight-likely": df_sample["flight_flag"].sum(),
        "Unexplained": df_sample["unknown_flag"].sum()
    }

    df_counts2 = pd.DataFrame(list(counts2.items()), columns=["Type", "Count"])

    bar_chart2 = alt.Chart(df_counts2).mark_bar().encode(
        x=alt.X("Type:N", title=None),
        y=alt.Y("Count:Q"),
        color=alt.Color("Type:N", scale=alt.Scale(domain=["Flight-likely", "Unexplained"],
                                                  range=["blue", "violet"])),
        tooltip=["Type", "Count"]
    ).properties(
        width=400,
        height=300
    )

    st.altair_chart(bar_chart2, use_container_width=True)

    st.markdown(
        "A clear side-by-side comparison of **explained vs. unexplained sightings**. Shows how much of the dataset aligns with plausible air traffic sources."
    )

        # â”€â”€ Correlation Plot: Flight-Likely & Unexplained vs Scaled Air Traffic â”€
    df["month"] = pd.to_datetime(df["ts"]).dt.to_period("M").dt.to_timestamp()

    grouped = (
        df.groupby("month")
        .agg(
            flight_likely=("flight_flag", "sum"),
            unexplained=("unknown_flag", "sum"),
            avg_traffic=("traffic_total", "mean")
        )
        .reset_index()
    ).dropna()

    # Scale avg_traffic for better visual comparison
    grouped["avg_traffic_scaled"] = grouped["avg_traffic"] / 1000  # Convert to thousands

    src = ColumnDataSource(grouped)

    p = figure(x_axis_type="datetime", height=350, sizing_mode="stretch_width")

    # Primary y-axis (Sightings)
    p.line("month", "flight_likely", source=src, color=Category10[3][0],
           line_width=2, legend_label="Flight-Likely Sightings")
    p.line("month", "unexplained", source=src, color=Category10[3][1],
           line_width=2, legend_label="Unexplained Sightings")

    # Right y-axis: Scaled avg_traffic
    tr_min, tr_max = grouped["avg_traffic_scaled"].min(), grouped["avg_traffic_scaled"].max()
    p.extra_y_ranges = {"traffic": Range1d(tr_min - 1, tr_max + 1)}
    p.add_layout(LinearAxis(y_range_name="traffic", axis_label="Avg Air Traffic (Ã—1000)"), "right")

    p.line("month", "avg_traffic_scaled", source=src, color=Category10[3][2],
           line_width=2, line_dash="dashed", y_range_name="traffic",
           legend_label="Avg Air Traffic")

    # Formatting
    p.xaxis.formatter = DatetimeTickFormatter(months="%b %Y")
    p.yaxis[0].axis_label = "Sightings Count"
    p.yaxis[1].formatter = NumeralTickFormatter(format="0.0")
    p.legend.location = "top_left"

    st.subheader("ğŸ“‰ Time Series: Sightings Over Time with Avg Air Traffic")
    st.bokeh_chart(p)

    st.markdown(
        "Compares **Flight-likely and Unexplained sightings over time**, plotted alongside **scaled air traffic** to evaluate overlapping trends and assess if unexplained reports follow flight density patterns."
    )

    
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• Tab 3â€“ Light-Pollution Analysis â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if tab_index == 2:
    st.subheader("ğŸŒƒ Distribution of Light-Pollution by Sighting Type")

    # â€” 1) grab the three groups, filter out invalids
    groups = {
        "Meteor-likely": df.loc[df["meteor_flag"],   "light_pollution"],
        "Flight-likely": df.loc[df["flight_flag"],   "light_pollution"],
        "Unexplained":   df.loc[df["unknown_flag"],  "light_pollution"],
    }
    # drop NaN / inf
    for k, s in groups.items():
        groups[k] = s.replace([np.inf, -np.inf], np.nan).dropna()

    # â€” 2) merge all values to compute percentile-based cap
    all_vals = pd.concat(groups.values())
    if all_vals.empty:
        st.info("No light-pollution data available for these filters.")
    else:
        cap = np.percentile(all_vals, 99)               # 99th percentile cap
        floor = np.percentile(all_vals, 1)              # 1st percentile floor
        bins = np.linspace(floor, cap, 25)              # 24 bins between 1% and 99%

        p4 = figure(
            height=350, sizing_mode="stretch_width",
            x_axis_label="Radiance (VIIRS)", 
            y_axis_label="Count of Sightings"
        )

        colors = {
            "Meteor-likely": "orange",
            "Flight-likely": "blue",
            "Unexplained":   "gray"
        }

        # â€” 3) for each group, compute histogram on the capped range and draw a quad
        for label, vals in groups.items():
            # cap values > cap and < floor into the first/last bin
            clipped = np.clip(vals.values, floor, cap)
            counts, edges = np.histogram(clipped, bins=bins)
            # draw quads between edges[i] and edges[i+1]
            p4.quad(
                top=counts, bottom=0,
                left=edges[:-1], right=edges[1:],
                fill_color=colors[label], line_color=None,
                fill_alpha=0.6,
                legend_label=label
            )

        p4.legend.location = "top_right"
        p4.legend.click_policy = "hide"
        st.bokeh_chart(p4)

        st.markdown("""
    Compares the **light pollution levels** (measured as VIIRS radiance) across three sighting categories:
    - Meteor-likely (orange)
    - Flight-likely (blue)
    - Unexplained (gray)  
    Histograms reveal whether sightings are more common in dark-sky or light-polluted areas.
    """
    )

    st.subheader("ğŸ—ºï¸ Map of Recent Sightings Colored by Light-Pollution")
    df4 = df_sample.dropna(subset=["light_pollution"])
    if df4.empty:
        st.info("No light-pollution values on recent sightings.")
    else:
        cmap = linear.YlOrRd_09.scale(
            df4["light_pollution"].min(),
            df4["light_pollution"].quantile(0.99)  # same cap here
        )
        m4 = folium.Map(location=[20,0], zoom_start=2, tiles="CartoDB.Positron")
        for _, r in df4.iterrows():
            val = r["light_pollution"]
            shown = min(val, cap)
            CircleMarker(
                (r["location"]["lat"], r["location"]["lon"]),
                radius=5,
                fill=True, fill_opacity=0.8,
                color=cmap(shown),
                popup=f"Radiance: {val:.2f}"
            ).add_to(m4)

        # ğŸ”§ ADD LEGEND HERE
        cmap.caption = "Radiance (VIIRS) - Light Pollution"
        cmap.add_to(m4)

        st_folium(m4, width=900, height=500)
    st.markdown("Displays recent UFO reports on a world map, colored by **measured radiance levels**. Useful for spotting patterns in how ambient light might influence report frequency or type."
    )
    
    st.subheader("ğŸ“ˆ Cumulative Distribution of Light-Pollution")

    cdf_plot = figure(
        height=300, sizing_mode="stretch_width",
        x_axis_label="Radiance (VIIRS)",
        y_axis_label="Cumulative Proportion"
    )

    for label, vals in groups.items():
        sorted_vals = np.sort(np.clip(vals.values, floor, cap))
        cdf = np.arange(1, len(sorted_vals)+1) / len(sorted_vals)
        cdf_plot.line(sorted_vals, cdf, legend_label=label, line_width=2, line_color=colors[label])

    cdf_plot.legend.location = "bottom_right"
    st.bokeh_chart(cdf_plot)

    st.markdown("Plots **CDFs** of light pollution values for each category. This helps assess what proportion of sightings occur under low-light vs. high-light conditions and whether Unexplained sightings differ meaningfully.")

    st.markdown("## Summary of Insights & Visualizations")
    st.markdown("""
    ### ğŸŒƒ Light Pollution Distribution by Sighting Type
    Compares the **light pollution levels** (measured as VIIRS radiance) across three sighting categories:
    - Meteor-likely (orange)
    - Flight-likely (blue)
    - Unexplained (gray)  
    Histograms reveal whether sightings are more common in dark-sky or light-polluted areas.

    ### ğŸ—ºï¸ Map of Recent Sightings Colored by Light Pollution
    Displays recent UFO reports on a world map, colored by **measured radiance levels**. Useful for spotting patterns in how ambient light might influence report frequency or type.

    ### ğŸ“ˆ Cumulative Distribution of Light Pollution
    Plots **CDFs** of light pollution values for each category. This helps assess what proportion of sightings occur under low-light vs. high-light conditions and whether Unexplained sightings differ meaningfully.
    """)

    

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• Tab 4 â€“ General Statistics â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if tab_index == 3:
    groups = {
        "Meteor-likely": df.loc[df["meteor_flag"],   "light_pollution"],
        "Flight-likely": df.loc[df["flight_flag"],   "light_pollution"],
        "Unexplained":   df.loc[df["unknown_flag"],  "light_pollution"],
    }

    st.subheader("ğŸŒ Top Countries with Most UFO Sightings")
    df_countries = df.dropna(subset=['Country'])
    top_countries = df_countries['Country'].value_counts().head(10)
    st.bar_chart(top_countries)

    st.markdown("Displays the **top 10 countries** with the highest number of sightings. Highlights regions with consistent or high reporting activity.")

    st.markdown("### ğŸ“Š Summary Statistics by Sighting Type")

    stats_df = pd.DataFrame({
        label: {
            "Count": len(vals),
            "Mean": vals.mean(),
            "Median": vals.median(),
            "Std Dev": vals.std(),
            "Min": vals.min(),
            "Max": vals.max(),
        }
        for label, vals in groups.items()
    }).T

    st.dataframe(stats_df.style.format("{:.2f}"))

    st.markdown("""
    Provides **descriptive statistics** (count, mean, median, etc.) of **light pollution values** for:
    - Meteor-likely
    - Flight-likely
    - Unexplained sightings  
    Helpful to compare environmental conditions surrounding each sighting type.
    """)

    st.subheader("ğŸ›¸ Distribution of UFO Shapes (Top 7)")

    df_shapes = df.dropna(subset=['shape'])
    shape_counts = df_shapes['shape'].value_counts().head(7)

    fig, ax = plt.subplots(figsize=(8, 4))
    shape_counts.sort_values().plot.barh(color='skyblue', ax=ax)
    ax.set_xlabel("Number of Sightings")
    ax.set_ylabel("UFO Shape")
    ax.set_title("Top 7 UFO Shapes by Frequency")
    st.pyplot(fig)

    st.markdown("Bar chart of the **top 7 most reported UFO shapes** based on user descriptions. Reveals potential consistency (or variety) in perceived UFO appearances.")

    
